{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': '/opt/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/breast_cancer.csv'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds= pd.DataFrame(data[\"data\"],data[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.columns=data[\"feature_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0         17.99         10.38          122.80     1001.0          0.11840   \n",
       "0         20.57         17.77          132.90     1326.0          0.08474   \n",
       "0         19.69         21.25          130.00     1203.0          0.10960   \n",
       "0         11.42         20.38           77.58      386.1          0.14250   \n",
       "0         20.29         14.34          135.10     1297.0          0.10030   \n",
       "..          ...           ...             ...        ...              ...   \n",
       "0         21.56         22.39          142.00     1479.0          0.11100   \n",
       "0         20.13         28.25          131.20     1261.0          0.09780   \n",
       "0         16.60         28.08          108.30      858.1          0.08455   \n",
       "0         20.60         29.33          140.10     1265.0          0.11780   \n",
       "1          7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "    mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.27760         0.30010              0.14710         0.2419   \n",
       "0            0.07864         0.08690              0.07017         0.1812   \n",
       "0            0.15990         0.19740              0.12790         0.2069   \n",
       "0            0.28390         0.24140              0.10520         0.2597   \n",
       "0            0.13280         0.19800              0.10430         0.1809   \n",
       "..               ...             ...                  ...            ...   \n",
       "0            0.11590         0.24390              0.13890         0.1726   \n",
       "0            0.10340         0.14400              0.09791         0.1752   \n",
       "0            0.10230         0.09251              0.05302         0.1590   \n",
       "0            0.27700         0.35140              0.15200         0.2397   \n",
       "1            0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "    mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                  0.07871  ...        25.380          17.33           184.60   \n",
       "0                  0.05667  ...        24.990          23.41           158.80   \n",
       "0                  0.05999  ...        23.570          25.53           152.50   \n",
       "0                  0.09744  ...        14.910          26.50            98.87   \n",
       "0                  0.05883  ...        22.540          16.67           152.20   \n",
       "..                     ...  ...           ...            ...              ...   \n",
       "0                  0.05623  ...        25.450          26.40           166.10   \n",
       "0                  0.05533  ...        23.690          38.25           155.00   \n",
       "0                  0.05648  ...        18.980          34.12           126.70   \n",
       "0                  0.07016  ...        25.740          39.42           184.60   \n",
       "1                  0.05884  ...         9.456          30.37            59.16   \n",
       "\n",
       "    worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0       2019.0           0.16220            0.66560           0.7119   \n",
       "0       1956.0           0.12380            0.18660           0.2416   \n",
       "0       1709.0           0.14440            0.42450           0.4504   \n",
       "0        567.7           0.20980            0.86630           0.6869   \n",
       "0       1575.0           0.13740            0.20500           0.4000   \n",
       "..         ...               ...                ...              ...   \n",
       "0       2027.0           0.14100            0.21130           0.4107   \n",
       "0       1731.0           0.11660            0.19220           0.3215   \n",
       "0       1124.0           0.11390            0.30940           0.3403   \n",
       "0       1821.0           0.16500            0.86810           0.9387   \n",
       "1        268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "    worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                 0.2654          0.4601                  0.11890  \n",
       "0                 0.1860          0.2750                  0.08902  \n",
       "0                 0.2430          0.3613                  0.08758  \n",
       "0                 0.2575          0.6638                  0.17300  \n",
       "0                 0.1625          0.2364                  0.07678  \n",
       "..                   ...             ...                      ...  \n",
       "0                 0.2216          0.2060                  0.07115  \n",
       "0                 0.1628          0.2572                  0.06637  \n",
       "0                 0.1418          0.2218                  0.07820  \n",
       "0                 0.2650          0.4087                  0.12400  \n",
       "1                 0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.set_index(data[\"target\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0         17.99         10.38          122.80     1001.0          0.11840   \n",
       "0         20.57         17.77          132.90     1326.0          0.08474   \n",
       "0         19.69         21.25          130.00     1203.0          0.10960   \n",
       "0         11.42         20.38           77.58      386.1          0.14250   \n",
       "0         20.29         14.34          135.10     1297.0          0.10030   \n",
       "..          ...           ...             ...        ...              ...   \n",
       "0         21.56         22.39          142.00     1479.0          0.11100   \n",
       "0         20.13         28.25          131.20     1261.0          0.09780   \n",
       "0         16.60         28.08          108.30      858.1          0.08455   \n",
       "0         20.60         29.33          140.10     1265.0          0.11780   \n",
       "1          7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "    mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.27760         0.30010              0.14710         0.2419   \n",
       "0            0.07864         0.08690              0.07017         0.1812   \n",
       "0            0.15990         0.19740              0.12790         0.2069   \n",
       "0            0.28390         0.24140              0.10520         0.2597   \n",
       "0            0.13280         0.19800              0.10430         0.1809   \n",
       "..               ...             ...                  ...            ...   \n",
       "0            0.11590         0.24390              0.13890         0.1726   \n",
       "0            0.10340         0.14400              0.09791         0.1752   \n",
       "0            0.10230         0.09251              0.05302         0.1590   \n",
       "0            0.27700         0.35140              0.15200         0.2397   \n",
       "1            0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "    mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                  0.07871  ...        25.380          17.33           184.60   \n",
       "0                  0.05667  ...        24.990          23.41           158.80   \n",
       "0                  0.05999  ...        23.570          25.53           152.50   \n",
       "0                  0.09744  ...        14.910          26.50            98.87   \n",
       "0                  0.05883  ...        22.540          16.67           152.20   \n",
       "..                     ...  ...           ...            ...              ...   \n",
       "0                  0.05623  ...        25.450          26.40           166.10   \n",
       "0                  0.05533  ...        23.690          38.25           155.00   \n",
       "0                  0.05648  ...        18.980          34.12           126.70   \n",
       "0                  0.07016  ...        25.740          39.42           184.60   \n",
       "1                  0.05884  ...         9.456          30.37            59.16   \n",
       "\n",
       "    worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0       2019.0           0.16220            0.66560           0.7119   \n",
       "0       1956.0           0.12380            0.18660           0.2416   \n",
       "0       1709.0           0.14440            0.42450           0.4504   \n",
       "0        567.7           0.20980            0.86630           0.6869   \n",
       "0       1575.0           0.13740            0.20500           0.4000   \n",
       "..         ...               ...                ...              ...   \n",
       "0       2027.0           0.14100            0.21130           0.4107   \n",
       "0       1731.0           0.11660            0.19220           0.3215   \n",
       "0       1124.0           0.11390            0.30940           0.3403   \n",
       "0       1821.0           0.16500            0.86810           0.9387   \n",
       "1        268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "    worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                 0.2654          0.4601                  0.11890  \n",
       "0                 0.1860          0.2750                  0.08902  \n",
       "0                 0.2430          0.3613                  0.08758  \n",
       "0                 0.2575          0.6638                  0.17300  \n",
       "0                 0.1625          0.2364                  0.07678  \n",
       "..                   ...             ...                      ...  \n",
       "0                 0.2216          0.2060                  0.07115  \n",
       "0                 0.1628          0.2572                  0.06637  \n",
       "0                 0.1418          0.2218                  0.07820  \n",
       "0                 0.2650          0.4087                  0.12400  \n",
       "1                 0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds\n",
    "# Split dataset X (Independent) & Y (Dependent)\n",
    "X = dataset[dataset.columns[:]].values # Independent Variable [ strt:end columns which are independent ]\n",
    "Y = dataset.index.values.reshape(-1,1) # Dependent Variable [column which is dependent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset  into training and test\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size =0.2 , random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=300,random_state=0)\n",
    "regressor.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812471815560606"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y,regressor.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clasifier = DecisionTreeClassifier(criterion=\"entropy\", random_state=0)\n",
    "clasifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.939855187357962"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y,clasifier.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logClassifier = LogisticRegression(random_state=0)\n",
    "logClassifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8195655620738862"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y,logClassifier.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel=\"linear\",random_state=0)\n",
    "svm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496379683949051"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y,svm.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5,metric=\"euclidean\",) # metric [minkowski,eucledian] \n",
    "knn.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Ways to get Accuracy/Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classifier Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9472759226713533"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[193,  19],\n",
       "       [ 11, 346]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y,knn.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9472759226713533"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.accuracy_score(Y, knn.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Jaccard Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9472759226713533"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(Y, knn.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       212\n",
      "           1       0.95      0.97      0.96       357\n",
      "\n",
      "    accuracy                           0.95       569\n",
      "   macro avg       0.95      0.94      0.94       569\n",
      "weighted avg       0.95      0.95      0.95       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y, knn.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navie Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9437609841827768"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B= np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 30 and input n_features is 2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-3d69a0b5a77e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plt.contourf(A, B, clasifier.predict(np.array([A.ravel(), B.ravel()]).T).reshape(A.shape),\n\u001b[0m\u001b[1;32m      2\u001b[0m              alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \"\"\"\n\u001b[1;32m    429\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    400\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 30 and input n_features is 2 "
     ]
    }
   ],
   "source": [
    "plt.contourf(A, B, clasifier.predict(np.array([A.ravel(), B.ravel()]).T).reshape(A.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6036930, 2)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([A.ravel(), B.ravel()]).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n",
      "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_train, Y_train\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "plt.contourf(X1, X2, clasifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "plt.title('Logistic Regression (Training set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Estimated Salary')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 30 and input n_features is 2 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-296b33eacad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m plt.contourf(X1, X2, clasifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n\u001b[0m\u001b[1;32m      2\u001b[0m             alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \"\"\"\n\u001b[1;32m    429\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tree_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    400\u001b[0m                              \u001b[0;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                              \u001b[0;34m\"input n_features is %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 30 and input n_features is 2 "
     ]
    }
   ],
   "source": [
    "plt.contourf(X1, X2, clasifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n",
    "            alpha = 0.75, cmap = ListedColormap(('red', 'green')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'join'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-7e96159b3c2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean compactness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                \u001b[0mhue\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"bengin\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                data = X_test.join(y_test,how=\"outer\"))\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'join'"
     ]
    }
   ],
   "source": [
    "sns.scatterplot(x=\"mean area\",\n",
    "               y=\"mean compactness\",\n",
    "               hue =\"bengin\",\n",
    "               data = X_test.join(y_test,how=\"outer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset X (Independent) & Y (Dependent)\n",
    "X = dataset[dataset.columns[0:1]].values # Independent Variable [ strt:end columns which are independent ]\n",
    "Y = dataset[dataset.columns[1:2]].values # Dependent Variable [column which is dependent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset  into training and test\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size =1/3 , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement  Classifier\n",
    "regressor = #Any model\n",
    "regressor.fit(X_train,Y_train) # learning\n",
    "Y_predict=regressor.predict(X_test) # prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Graph\n",
    "plt.scatter(X_train,Y_train,color = \"red\")\n",
    "plt.plot(X_train,regressor.predict(X_train),color=\"blue\") # best fit line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R squared value\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y_test,Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
